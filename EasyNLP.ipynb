{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EasyNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5D2nBBb8FCI"
      },
      "source": [
        "\n",
        "\n",
        "HOW TO USE\n",
        "\n",
        "1) Optional: (To make this run faster) At the top left, click \"Runtime\"-> \"Change runtime type\", change hardware accelerator to \"GPU\" and change Runtime-shape to \"High-RAM\"\n",
        "\n",
        "2) Run the Imports cell block below (click the thing that looks like a play button of click shift+Enter\n",
        "\n",
        "3) Put your text in the input field of for the cell block with the task you want\n",
        "\n",
        "4) Run that cell block (Shift+Enter)\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa8PUqHAb4L7",
        "cellView": "form"
      },
      "source": [
        "#@title Imports - RUN THIS FIRST\n",
        "\n",
        "!pip install huggingface\n",
        "!pip install transformers\n",
        "\n",
        "from google.colab import output\n",
        "from transformers import AutoTokenizer, DPRQuestionEncoder, AutoModelWithLMHead\n",
        "import transformers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "output.clear()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yde3uUt-7I9k"
      },
      "source": [
        "#@title Sentiment Analysis\n",
        "\n",
        "text = \"Some say that often times, it do be like it do\" #@param {type:\"string\"}\n",
        "\n",
        "# Load Model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Generate Answer\n",
        "sentiment = sentiment_model(text)[0]\n",
        "\n",
        "# Print Answer\n",
        "print(sentiment)\n",
        "print(\"\\n\\n Sentiment:\\n\")\n",
        "print(sentiment)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJvXCu4BzRdN",
        "cellView": "form"
      },
      "source": [
        "#@title Context-Based Question Answering\n",
        "\n",
        "context = \"Some say that often times, it do be like it do\" #@param {type:\"string\"}\n",
        "question = \"What it do baby\" #@param {type:\"string\"}\n",
        "\n",
        "# Load Model\n",
        "qna = pipeline(\"question-answering\")\n",
        "\n",
        "# Generate Answer\n",
        "answer = qna(question=question, context=context)\n",
        "\n",
        "# Print Answer\n",
        "print(answer)\n",
        "print(\"\\n\\n Answer:\\n\")\n",
        "print(answer['answer'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "OOIr9AFr1WfG"
      },
      "source": [
        "#@title Article Summarizatrion\n",
        "\n",
        "article = \"A more than 12,000% rally this year in dogecoin, a cryptocurrency that was set up as a joke and serves no purpose, sent its price to a record 69 cents per token this week. Bitcoin climbed briefly to over $60,000 apiece last month, more than doubling its price since the end of 2020. That is prompting investors to turn their attention to newer digital assets such as DigiByte, VeChain and SafeMoon in the hunt for cheaper alternatives that could be the next to skyrocket.\" #@param {type:\"string\"}\n",
        "article = article + \".\"\n",
        "\n",
        "if len(article.split()) <= 256:\n",
        "  max_len = 256\n",
        "elif len(article.split()) <= 512:\n",
        "  max_len = 512\n",
        "elif len(article.split()) <= 1024:\n",
        "  max_len = 1024\n",
        "elif len(article.split()) <= 2048:\n",
        "  max_len = 2048\n",
        "elif len(article.split()) <= 4096:\n",
        "  max_len = 4096\n",
        "elif len(article.split()) <= 8192:\n",
        "  max_len = 8192\n",
        "else:\n",
        "  print(\"Bruh your article is so long chill out. I'm gonna clip it to 8192 words\")\n",
        "  tmp = \"\"\n",
        "  article = article.split()\n",
        "  for i in range(8192):\n",
        "    tmp = tmp + article[i]\n",
        "  max_len = 8192\n",
        "\n",
        "  \n",
        "# Load Model\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Generate Summary\n",
        "summary = summarizer(article, max_length=1024, min_length=4, do_sample=False)\n",
        "output.clear()\n",
        "\n",
        "# Print Summary\n",
        "print(\"\\nSummary:\")\n",
        "print(summary[0][\"summary_text\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmGMCbSf2Gvh",
        "cellView": "form"
      },
      "source": [
        "#@title Named Entity Recognition\n",
        "\n",
        "sequence = \"Imagine if Elon Musk put a DogeCoin on Mars. That'd be so lit.\" #@param {type:\"string\"}\n",
        "\n",
        "# Load Model\n",
        "ner = pipeline(\"ner\")\n",
        "\n",
        "# Generate Entities\n",
        "entities = ner(sequence)\n",
        "\n",
        "# Print Entities\n",
        "for entity in entities:\n",
        "  print(entity)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "sUlG-mBlpQyJ"
      },
      "source": [
        "#@title Text Generation\n",
        "\n",
        "prompt = \"In 2021, DogeCoin took off and some believe it may shortly reach the moon.\" #@param {type:\"string\"}\n",
        "start_of_sentence = \"Today, Dogecoin\" #@param {type:\"string\"}\n",
        "generation_length = 100 #@param {type:\"integer\"}\n",
        "\n",
        "# Load Model\n",
        "model = AutoModelWithLMHead.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "# Generate Input\n",
        "x_tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "inputs = x_tokenizer.encode(prompt + start_of_sentence, add_special_tokens=False, return_tensors=\"pt\")\n",
        "prompt_length = len(x_tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
        "\n",
        "# Generate Answer\n",
        "outputs = model.generate(inputs, max_length=generation_length, do_sample=True, top_p=0.95, top_k=60)\n",
        "generated = prompt + x_tokenizer.decode(outputs[0])[prompt_length:]\n",
        "\n",
        "# Print Answer\n",
        "print(generated)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sc-WQAg77Nw"
      },
      "source": [
        "Citation\n",
        "\n",
        "@inproceedings{wolf-etal-2020-transformers,\n",
        "    title = \"Transformers: State-of-the-Art Natural Language Processing\",\n",
        "    author = \"Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\",\n",
        "    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\",\n",
        "    month = oct,\n",
        "    year = \"2020\",\n",
        "    address = \"Online\",\n",
        "    publisher = \"Association for Computational Linguistics\",\n",
        "    url = \"https://www.aclweb.org/anthology/2020.emnlp-demos.6\",\n",
        "    pages = \"38--45\"\n",
        "}"
      ]
    }
  ]
}