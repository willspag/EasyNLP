{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EasyNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5D2nBBb8FCI"
      },
      "source": [
        "\n",
        "\n",
        "HOW TO USE\n",
        "\n",
        "1) Optional: (To make this run faster) At the top left, click \"Runtime\"-> \"Change runtime type\", change hardware accelerator to \"GPU\" and change Runtime-shape to \"High-RAM\"\n",
        "\n",
        "2) Run the Imports cell block below (click the thing that looks like a play button of click shift+Enter\n",
        "\n",
        "3) Put your text in the input field of for the cell block with the task you want\n",
        "\n",
        "4) Run that cell block (Shift+Enter)\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Pa8PUqHAb4L7"
      },
      "source": [
        "#@title Imports - RUN THIS FIRST\n",
        "\n",
        "from google.colab import output\n",
        "from transformers import AutoTokenizer, DPRQuestionEncoder\n",
        "import transformers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import pipeline\n",
        "\n",
        "!pip install huggingface\n",
        "!pip install transformers\n",
        "\n",
        "output.clear()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "yde3uUt-7I9k",
        "outputId": "e3a7eb5f-67d0-42b5-9922-eee29a27b3b4"
      },
      "source": [
        "#@title Sentiment Analysis\n",
        "\n",
        "text = \"Some say that often times, it do be like it do\" #@param {type:\"string\"}\n",
        "\n",
        "# Load Model\n",
        "sentiment_model = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Generate Answer\n",
        "sentiment = sentiment_model(text)[0]\n",
        "\n",
        "# Print Answer\n",
        "print(sentiment)\n",
        "print(\"\\n\\n Sentiment:\\n\")\n",
        "print(sentiment)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'label': 'POSITIVE', 'score': 0.9986860752105713}\n",
            "\n",
            "\n",
            " Sentiment:\n",
            "\n",
            "{'label': 'POSITIVE', 'score': 0.9986860752105713}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "iJvXCu4BzRdN",
        "outputId": "be15e985-3fda-4093-dac2-fe81be5b8539"
      },
      "source": [
        "#@title Context-Based Question Answering\n",
        "\n",
        "context = \"Some say that often times, it do be like it do\" #@param {type:\"string\"}\n",
        "question = \"What it do baby\" #@param {type:\"string\"}\n",
        "\n",
        "# Load Model\n",
        "qna = pipeline(\"question-answering\")\n",
        "\n",
        "# Generate Answer\n",
        "answer = qna(question=question, context=context)\n",
        "\n",
        "# Print Answer\n",
        "print(answer)\n",
        "print(\"\\n\\n Answer:\\n\")\n",
        "print(answer['answer'])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'score': 0.7321708798408508, 'start': 27, 'end': 46, 'answer': 'it do be like it do'}\n",
            "\n",
            "\n",
            " Answer:\n",
            "\n",
            "it do be like it do\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "OOIr9AFr1WfG",
        "outputId": "a7f06b85-1ced-4e0a-bdfb-8632d9f83ec2"
      },
      "source": [
        "#@title Article Summarizatrion\n",
        "\n",
        "article = \"A more than 12,000% rally this year in dogecoin, a cryptocurrency that was set up as a joke and serves no purpose, sent its price to a record 69 cents per token this week. Bitcoin climbed briefly to over $60,000 apiece last month, more than doubling its price since the end of 2020. That is prompting investors to turn their attention to newer digital assets such as DigiByte, VeChain and SafeMoon in the hunt for cheaper alternatives that could be the next to skyrocket.\" #@param {type:\"string\"}\n",
        "article = article + \".\"\n",
        "\n",
        "if len(article.split()) <= 256:\n",
        "  max_len = 256\n",
        "elif len(article.split()) <= 512:\n",
        "  max_len = 512\n",
        "elif len(article.split()) <= 1024:\n",
        "  max_len = 1024\n",
        "elif len(article.split()) <= 2048:\n",
        "  max_len = 2048\n",
        "elif len(article.split()) <= 4096:\n",
        "  max_len = 4096\n",
        "elif len(article.split()) <= 8192:\n",
        "  max_len = 8192\n",
        "else:\n",
        "  print(\"Bruh your article is so long chill out. I'm gonna clip it to 8192 words\")\n",
        "  tmp = \"\"\n",
        "  article = article.split()\n",
        "  for i in range(8192):\n",
        "    tmp = tmp + article[i]\n",
        "  max_len = 8192\n",
        "\n",
        "  \n",
        "# Load Model\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Generate Summary\n",
        "summary = summarizer(article, max_length=1024, min_length=4, do_sample=False)\n",
        "output.clear()\n",
        "\n",
        "# Print Summary\n",
        "print(\"\\nSummary:\")\n",
        "print(summary[0][\"summary_text\"])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Summary:\n",
            " A more than 12,000% rally this year in dogecoin sent its price to a record 69 cents per token this week . Bitcoin climbed briefly to over $60,000 apiece last month, more than doubling its price since the end of 2020 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "ZmGMCbSf2Gvh",
        "outputId": "45600d44-b020-47ec-9a1b-44e17ff68618"
      },
      "source": [
        "#@title Named Entity Recognition\n",
        "\n",
        "sequence = \"Imagine if Elon Musk put a DogeCoin on Mars. That'd be so lit.\" #@param {type:\"string\"}\n",
        "\n",
        "# Load Model\n",
        "ner = pipeline(\"ner\")\n",
        "\n",
        "# Generate Entities\n",
        "entities = ner(sequence)\n",
        "\n",
        "# Print Entities\n",
        "for entity in entities:\n",
        "  print(entity)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'word': 'El', 'score': 0.9986462593078613, 'entity': 'I-PER', 'index': 3, 'start': 11, 'end': 13}\n",
            "{'word': '##on', 'score': 0.9972710609436035, 'entity': 'I-PER', 'index': 4, 'start': 13, 'end': 15}\n",
            "{'word': 'Mu', 'score': 0.9950355887413025, 'entity': 'I-PER', 'index': 5, 'start': 16, 'end': 18}\n",
            "{'word': '##sk', 'score': 0.9711271524429321, 'entity': 'I-PER', 'index': 6, 'start': 18, 'end': 20}\n",
            "{'word': 'Dog', 'score': 0.5977500081062317, 'entity': 'I-MISC', 'index': 9, 'start': 27, 'end': 30}\n",
            "{'word': '##e', 'score': 0.9452806711196899, 'entity': 'I-MISC', 'index': 10, 'start': 30, 'end': 31}\n",
            "{'word': '##C', 'score': 0.8719401359558105, 'entity': 'I-MISC', 'index': 11, 'start': 31, 'end': 32}\n",
            "{'word': '##oi', 'score': 0.6306234002113342, 'entity': 'I-MISC', 'index': 12, 'start': 32, 'end': 34}\n",
            "{'word': '##n', 'score': 0.9417673349380493, 'entity': 'I-MISC', 'index': 13, 'start': 34, 'end': 35}\n",
            "{'word': 'Mars', 'score': 0.9974361658096313, 'entity': 'I-LOC', 'index': 15, 'start': 39, 'end': 43}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sc-WQAg77Nw"
      },
      "source": [
        "Citation\n",
        "\n",
        "@inproceedings{wolf-etal-2020-transformers,\n",
        "    title = \"Transformers: State-of-the-Art Natural Language Processing\",\n",
        "    author = \"Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush\",\n",
        "    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations\",\n",
        "    month = oct,\n",
        "    year = \"2020\",\n",
        "    address = \"Online\",\n",
        "    publisher = \"Association for Computational Linguistics\",\n",
        "    url = \"https://www.aclweb.org/anthology/2020.emnlp-demos.6\",\n",
        "    pages = \"38--45\"\n",
        "}"
      ]
    }
  ]
}